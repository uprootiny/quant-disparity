{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02: Full Layer Sweep on Llama-2-7B\n",
        "\n",
        "**Goal:** Find Llama's critical layers for multilingual fairness\n",
        "\n",
        "**Time:** ~2 hours on T4\n",
        "\n",
        "**Method:** Protect each layer individually, measure disparity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate tqdm\n",
        "\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "\n",
        "import torch\n",
        "import json\n",
        "from datetime import datetime\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from src.disparity import full_sweep, DEFAULT_TEXTS\n",
        "from src.quantize import get_num_layers\n",
        "from src.utils import save_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_ID = \"NousResearch/Llama-2-7b-hf\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "num_layers = get_num_layers(model)\n",
        "print(f\"Sweeping {num_layers} layers...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use subset of languages for speed\n",
        "TEXTS = {k: v for k, v in DEFAULT_TEXTS.items() if k in ['en', 'he', 'ar', 'zh']}\n",
        "\n",
        "# Full sweep\n",
        "results = full_sweep(model, tokenizer, TEXTS, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Results analysis\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"LAYER CRITICALITY RANKING\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\n{'Rank':<6} {'Layer':<8} {'Disparity':>12} {'Position':>10}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for rank, (layer, disp, _) in enumerate(results[:10], 1):\n",
        "    position = layer / (num_layers - 1) * 100\n",
        "    print(f\"{rank:<6} L{layer:<7} {disp:>11.2f}x {position:>9.0f}%\")\n",
        "\n",
        "# Top-3 critical layers\n",
        "top3 = [r[0] for r in results[:3]]\n",
        "print(f\"\\nTop-3 critical layers: {top3}\")\n",
        "\n",
        "# Compare with GPT-2 equivalent\n",
        "gpt2_equiv = [0, int(num_layers * 0.75), num_layers - 1]\n",
        "print(f\"GPT-2 equivalent (L0+75%+last): {gpt2_equiv}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results\n",
        "output = {\n",
        "    'model': MODEL_ID,\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'num_layers': num_layers,\n",
        "    'sweep_results': [(l, d) for l, d, _ in results],\n",
        "    'top_3': top3,\n",
        "    'gpt2_equivalent': gpt2_equiv,\n",
        "}\n",
        "\n",
        "save_results(output, 'layer_sweep_results.json')\n",
        "print(\"Results saved to layer_sweep_results.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "layers = [r[0] for r in results]\n",
        "disparities = [r[1] for r in results]\n",
        "\n",
        "# Sort by layer index for plotting\n",
        "sorted_data = sorted(zip(layers, disparities))\n",
        "layers_sorted = [x[0] for x in sorted_data]\n",
        "disp_sorted = [x[1] for x in sorted_data]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.bar(layers_sorted, disp_sorted)\n",
        "plt.axhline(y=1.0, color='r', linestyle='--', label='Parity (1.0x)')\n",
        "plt.xlabel('Layer Index')\n",
        "plt.ylabel('Disparity (lower = more critical)')\n",
        "plt.title(f'Layer Criticality: {MODEL_ID}')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('layer_sweep_plot.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
